---
title: "final-prediction"
author: "Helen Simpson"
date: "10/31/2020"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#county-level predictions for Pennsylvania, Nevada, Florida if time
#polling data source: https://projects[.]fivethirtyeight.com/polls/president-general/national/
#archive: https://web.archive.org/web/20201102021843/https://projects.fivethirtyeight[.]com/polls/president-general/national/
#for some reason, broom::glance() doesn't work on my new computer, but works on my old computer. This may have to do with package updating? In any case, if the code doesn't run for you, that may be why. Sorry.

library(tidyverse)
library(broom)
library(readxl)
library(usmap)
library(dvmisc)
library(tableHTML)

#data from 538
polls.2020.raw <- read_csv("./president_polls.csv")

#our master state-level dataset
all.data <- read_csv("./all_data.csv")
```

```{r}
#format poll data from 538

#process polls: convert date format, take only highly-graded polls, average over several polls by the same pollster on the same day, change data format so that each poll is one observation rather than two
polls.2020 <- polls.2020.raw %>% 
  mutate(start_date = as.Date(start_date, tryFormats = c("%m/%d/%y"))) %>% 
  filter(fte_grade %in% c("A+", "A", "A-", "A/B", "B+", "B", "B-", "B/C"), 
         candidate_party %in% c("DEM", "REP"),
         !is.na(state)) %>% 
  select(poll_id, cycle, state, pollster, fte_grade, sample_size, population, start_date, end_date, candidate_party, pct) %>% 
  group_by(poll_id, candidate_party) %>% 
  mutate(poll.ave = sum(pct)/length(pct),
         poll.num = length(pct)) %>% #several polls by the same pollster on the same day
  select(-pct) %>% 
  distinct() %>% 
  pivot_wider(names_from = candidate_party, values_from = poll.ave)

#get 30-day poll average
polls.030 <- polls.2020 %>% 
  filter(start_date > as.Date("2020-10-03")) %>% 
  group_by(state) %>% 
  arrange(state) %>% 
  mutate(rlead = REP - DEM,
         rlead.030 = sum(rlead / length(rlead)),
         new.30sum = sum(poll.num)) %>% 
  select(state, rlead.030, new.30sum) %>% 
  distinct()

#get more-than-30 day average
polls.30plus <- polls.2020 %>% 
  filter(start_date < as.Date("2020-10-03")) %>% 
  group_by(state) %>% 
  arrange(state) %>% 
  mutate(rlead = REP - DEM,
         rlead.30plus = sum(rlead / length(rlead)),
         new.30plus.sum = sum(poll.num)) %>% 
  select(state, rlead.30plus, new.30plus.sum) %>% 
  distinct()

pollave.2020 <- merge(polls.030, polls.30plus, all = TRUE)

#average polls for states with electoral votes by congressional district (Maine, Nebraska)
#actually there are state-wide polls...we'll just use those
# maine.data <- pollave.2020 %>% 
#   filter(state == "Maine CD-1" | state == "Maine CD-2") %>% 
#   mutate(rlead.030 = sum(rlead.030)/length(rlead.030),
#          rlead.30plus = sum(rlead.30plus)/length(rlead.30plus),
#          state = "Maine") %>% 
#   distinct()

nebraska.data <- pollave.2020 %>% 
  filter(state == "Nebraska CD-1" | state == "Nebraska CD-2") %>% 
  mutate(rlead.030 = rlead.030[2],
         rlead.30plus = sum(rlead.30plus)/length(rlead.30plus),
         state = "Nebraska") %>% 
  distinct()

# pollave.2020 <- merge(pollave.2020, maine.data, all = TRUE)
pollave.2020 <- merge(pollave.2020, nebraska.data, all = TRUE)

#filter out district-level polls
pollave.2020 <- pollave.2020 %>% filter(state != "Maine CD-1",
                                        state != "Maine CD-2",
                                        state != "Nebraska CD-1",
                                        state != "Nebraska CD-2")
```

```{r}
#format data, preliminary models

#take the things we need from all.data and format the df
#new.30sum and new.30plus.sum aren't used, but allow for these columns to be merged in the 2020 dataset so that these values can be carried through the data cleaning + merging process for use in the post-election analysis
state.data <- all.data %>% 
  select(year, state, R_pv2p, D_pv2p, prev_Rvote, prev_Dvote, ave.30plus, ave.030) %>% 
  rename(rlead.030 = ave.030,
         rlead.30plus = ave.30plus) %>% 
  filter(!is.na(R_pv2p), 
         !is.na(prev_Rvote), 
         year >= 1972) %>% 
  mutate(rlead.prev = prev_Rvote - prev_Dvote,
         rlead.vote = R_pv2p - D_pv2p,
         new.30sum = 0, 
         new.30plus.sum = 0) %>% 
  select(-R_pv2p, -D_pv2p, -prev_Rvote, -prev_Dvote)

#use all polls to stand in when polls from the last 30 days are not available
#filter out DC (no polls)
#this is NOT the dataset used for the actual loop model that produced the results/ charts
#this was a preliminary exploration
reg.data <- state.data %>%
  mutate(rlead.030 = case_when(is.na(rlead.030) ~ rlead.30plus,
                               !is.na(rlead.030) ~ rlead.030)) %>% 
  filter(state != "District of Columbia")

#vote = previous vote + 30-day polls
my.model.1 <- reg.data %>% 
  group_by(state) %>% 
  do(model = lm(rlead.vote ~ rlead.prev + rlead.030, .)) %>% 
  rowwise() %>% tidy(model)

#vote = previous vote + 30-day polls + more-than-30-day polls
my.model.2 <- reg.data %>% 
  group_by(state) %>% 
  do(model = lm(rlead.vote ~ rlead.prev + rlead.030 + rlead.30plus, .)) %>% 
  rowwise() %>% glance(model)
```

```{r}
#format and merge 2020 dataset

#get 2016 vote results for 2020's previous vote
vote.2016 <- state.data %>% 
  filter(year == 2016) %>% 
  select(state, rlead.vote) %>% 
  rename(rlead.prev = rlead.vote)

#merge 2016 results with rest of 2020 (polling) data
data.2020 <- merge(pollave.2020, vote.2016, all = TRUE)

#finish formatting 2020 dataset for prediction: year variable, vote results as N/a
data.2020 <- data.2020 %>% 
  mutate(year = 2020, 
         rlead.vote = 0, #a little hacky but I always have trouble with this
         rlead.vote = na_if(rlead.vote, 0))

#merge 2020 data with the master dataset
state.data <- rbind(state.data, data.2020)
```

```{r}
#preparing the new master dataset for regression: impute last 30 day polls using all polls when missing
reg.full.data <- state.data %>%
  mutate(used.poll.sum = case_when(!is.na(new.30sum) ~ new.30sum,
                                   is.na(new.30sum) ~ new.30plus.sum),
         rlead.030 = case_when(is.na(rlead.030) ~ rlead.30plus,
                               !is.na(rlead.030) ~ rlead.030))

used.poll.df <- reg.full.data %>% filter(year == 2020) %>% select(state, used.poll.sum)
write.csv(used.poll.df, "./used_poll_sum.csv", row.names = FALSE)

reg.full.data <- reg.full.data %>% select(-new.30sum, -new.30plus.sum, -used.poll.sum) %>% 
  group_by(state)

#failed attempt to use predict with do() instead of a loop

# my.model.1 <- reg.full.data %>% 
#   do(model = lm(rlead.vote ~ rlead.prev + rlead.030, .)) %>% 
#   rowwise() %>% tidy(model) %>% 
#   filter(state == "Alaska")

# my.predict <- tidy(predict(lm(rlead.vote ~ rlead.prev + rlead.030, data = reg.full.data), 
#         reg.full.data[reg.full.data$year == 2020,]))
#   
# test.data <- reg.full.data[reg.full.data$year == 2020,]
# 
# test.predict <- predict(my.model.1, state.data[year == 2020])
# pred_econ_inc <- predict(mod_econ_inc_, dat_econ_inc[dat_econ_inc$year == year,])

#split dataset into separate dfs for each state in preparation for loop
split.data <- split(reg.full.data, reg.full.data$state)
```

```{r warning=FALSE}
#this is the chunk where the loop/ main analysis takes place

#extract state names, now the names of each df
my.names <- names(split.data)

#create a df with just 0 that we can merge into
states.model <- data.frame(0)

#start a counter at zero for extracting names (might not work if you start at one? not sure)
loop <- 0

#LOOP for running state-level regressions, predictions, tests
for(df in split.data) {
  
  #get the state name by interating over the my.names list of state names and the "loop" counter
  my.state <- paste(my.names[loop + 1])
  
  #run the regression: predict state-level vote share with previous vote share and last 30 days of polls
  my.model <- lm(rlead.vote ~ rlead.prev + rlead.030, data = df)
  
  #store coefficients
  my.state.model <- tidy(my.model) %>% mutate(state = my.state)
  
  #store regression stats
  my.model.stats <- glance(my.model) %>% mutate(state = my.state)
  
  #merge coefficients and regression stats
  my.state.model <- merge(my.state.model, my.model.stats, all = TRUE)
  
  #get 2020 only data fot this state
  my.2020 <- df %>% filter(year == 2020)
  
  #predict! using the predict function. tidy to coerce to dataframe
  #this throws a warning (tidy + numeric deprecated), that's why warnings for this chunk are off
  state.predict <- tidy(predict(my.model, my.2020, interval = "confidence"))
  
  #move predict elements into the dataframe for this state (loop dataframe)
  my.state.model$my.predict <- state.predict$fit
  my.state.model$lwr <- state.predict$lwr
  my.state.model$upr <- state.predict$upr
  my.state.model$mse <- get_mse(my.model)
  
  # trying to impute predictions for states w/ missing polls by using previous vote only
  # for some reason, this still isn't working (I can't get states to stop showing up as 100%+) so it's commented out for now
  # my.prev <- df %>% filter(year == 2020)
  # my.prev <- my.prev$rlead.prev
  # 
  # my.state.model <- my.state.model %>% 
  #   mutate(my.predict = case_when(is.na(my.predict) ~ my.prev,
  #                                 !is.na(my.predict) ~ my.predict))

  #merge state loop dataframe with master dataframe
  states.model <- merge(states.model, my.state.model, all = TRUE)
  
# run out of sample fit (partially working)
# from class code, section 3 -- some help from Sam Thau's code as well
# year_list <- seq(from = 1972, to = 2016, by = 4)
# 
# year <- 1972
# outsamp_dflist <- lapply(year_list, function(year){
#   #true vote shares
#   oos.true <- df$rlead.vote[df$year == year]
# 
#   if (length(oos.true) > 0){
#     
#     #dataframes excluding the row (incumbency is backwards as everything is negated)
#     oos.df <- df %>% filter(!(year == year))
# 
#     #prediction dataframes
#     oos.p <- df %>% filter(year == year)
# 
#     #fundamental model out-of-sample prediction
#     oos.model <- lm(rlead.vote ~ rlead.prev + rlead.030, data = df )
#     oos.pred <- predict(oos.model, oos.p)
# 
#     c(year, 
#       margin_error = oos.pred - oos.true, 
#       winner_correct = ((oos.pred > 0) == (oos.true > 0))
#     )
#   }
# })
# 
#   outsamp_df <- do.call(rbind, outsamp_dflist)
# # colMeans(abs(outsamp_df[2:4]), na.rm=T) #
# # colMeans(outsamp_df[5:7], na.rm=T) ### classification accuracy
# 
# outsamp_df[,c("year","econ_winner_correct","poll_winner_correct","plus_winner_correct")] #
# 
# outsamp_dflist <- sapply(year_list, function(year){sapply(state_list, function(state) check_out(year,state))})
# 
# outsamp_df <- cbind("year", "state","fund_margin_error",
#                 "polls_margin_error","plus_margin_error","fund_correct","polls_correct","plus_correct")

  #iterate loop counter
  loop <- loop + 1
}

#clean up new master dataframe: get rid of placeholder zeros, filter out states w/ no polls and so no predict value (see explanation above)
states.model <- states.model %>%
  select(-X0) %>% 
  filter(!is.na(my.predict)) %>% 
  arrange(state, term)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#this chunck does the same as the chunk above but for a regression model with just polls (no previous vote) to compare predictions/ predicitive power
#results are ambiguous (certainly not uniformly good for the official = previous model)
#see comments in previous chunk for code explanation
#this chunck marked eval = false (will not run) because it's not needed for any of the blog post stuff and can cause confusion

my.names <- names(split.data)
states.model.2 <- data.frame(0)
loop <- 0

for(df in split.data) {
  my.state <- paste(my.names[loop + 1])
  
  my.model <- lm(rlead.vote ~ rlead.030, data = df)
  my.state.model <- tidy(my.model) %>% mutate(state = my.state)
  my.model.stats <- glance(my.model) %>% mutate(state = my.state)
  
  my.state.model <- merge(my.state.model, my.model.stats, all = TRUE)
  
  my.2020 <- df %>% filter(year == 2020)
  state.predict <- tidy(predict(my.model, my.2020, interval = "confidence"))
  my.state.model$my.predict <- state.predict$fit
  my.state.model$lwr <- state.predict$lwr
  my.state.model$upr <- state.predict$upr
  my.state.model$mse <- get_mse(my.model)
  
  
  my.prev <- df %>% filter(year == 2020)
  my.prev <- my.prev$rlead.prev
  
  #attempted solution to DC/ RI/ WY bug (see above)
  my.state.model <- my.state.model %>% 
    mutate(fake.my.prev = my.prev - 50,
           my.predict = case_when(is.na(my.predict) ~ fake.my.prev,
                                  !is.na(my.predict) ~ my.predict))

  
  states.model.2 <- merge(states.model.2, my.state.model, all = TRUE)
  loop <- loop + 1
}

states.model.2 <- states.model.2 %>% 
  select(-X0) %>% 
  arrange(state, term)
```

```{r}
#gather, format, and print tables for blog post
#print lines are commented out for ease of use, if you want to change a table just uncomment it
#note that you have to copy/ paste HTML output from here to your markdown document. see explanation in week 5

#table of point predictions, predictive interval
predict.table.df <- states.model %>% 
  select(state, my.predict, lwr, upr) %>%
  distinct() %>% 
  rename(State = state, `Point prediction` = my.predict, `Lower bound` = lwr, `Upper bound` = upr)

write.csv(predict.table.df, "./predict_table.csv", row.names = FALSE)

predict.table <- tableHTML(predict.table.df, rownames = FALSE, border = 2, round = 4)

# print(predict.table, viewer = FALSE)

#table of regression coefficients, significance for each state
coefficients.table.df <- states.model %>%
  select(state, term, estimate, std.error, p.value) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                             term == "rlead.030" ~ "Republican lead in last 30 days",
                             term == "rlead.prev" ~ "Republican win/loss margin in previous election")) %>% 
  filter(!is.na(term)) %>% 
  rename(State = state, Term = term, Estimate = estimate, `Std. error` = std.error, `p value` = p.value)

coefficients.table <- tableHTML(coefficients.table.df, rownames = FALSE, border = 2, round = 4)

# print(coefficients.table, viewer = FALSE)

#table with model summary statistics (r^2, mean squared error) for each state
fit.table.df <- states.model %>% 
  select(state, r.squared, adj.r.squared, mse) %>%
  filter(!is.na(r.squared)) %>% 
  rename(State = state, `r squared` = r.squared, `Adjusted r squared` = adj.r.squared, `Mean squared error` = mse)

fit.table <- tableHTML(fit.table.df, rownames = FALSE, border = 2, round = 4)

# print(fit.table, viewer = FALSE)
```

```{r}
#this chunck is for further processing of the prediction results
#the commented-out bit is for comparing the results of the vote share = polls + prev vote vs. vote share = polls models. make sure to run that chunk first

#generate interval size, point estimates for Trump/ Biden
predict.results <- states.model %>% 
  select(state, my.predict, lwr, upr) %>% 
  distinct() %>% 
  mutate(interval.size = upr - lwr,
         trump.predict = my.predict + 50, 
         biden.predict = 100 - trump.predict)

# predict.results.2 <- states.model.2 %>% 
#   select(state, my.predict, lwr, upr) %>% 
#   distinct() %>% 
#   mutate(interval.size = upr - lwr) %>% 
#   rename(my.predict.2 = my.predict, lwr.2 = lwr, upr.2 = upr, interval.size.2 = interval.size)

# my.test <- merge(predict.results, predict.results.2)
# my.test <- my.test %>% mutate(predict.diff = my.predict - my.predict.2,
#                               interval.diff = interval.size - interval.size.2)
# 
# my.test %>% ggplot(aes(x = predict.diff, y = interval.diff)) + geom_point() + theme_classic()
# hist(my.test$predict.diff)
# hist(my.test$interval.diff)
```

```{r}
#this chunck is for producing electoral college estimates

#bring in data on the electoral college
#from https://en.wikipedia[.]org/wiki/United_States_Electoral_College
#skip the first row, which has the source info in it
college <- read_excel("./electoralcollege.xlsx", skip = 1) %>% rename(state = State)

predict.results <- merge(predict.results, college, by = "state", all = TRUE)

#who wins each state, sum up electoral votes
predict.results <- predict.results %>% mutate(won = case_when(my.predict > 0 ~ 1,
                                                              my.predict < 0 ~ 0),
                                              total.votes = sum(won * ec.votes)) 

#translate predicitive intervals into electoral college estimates
#reminder that a number > 0 means the Republican (Trump) wins and vice versa
my.predict.results <- predict.results %>% 
  mutate(won.lwr = case_when(lwr > 0 ~ 1,
                             lwr < 0 ~ 0),
         won.lwr = case_when(!is.na(won.lwr) ~ won.lwr,
                             is.na(won.lwr) ~ won),
         total.votes.lwr = sum(won.lwr * ec.votes),
         won.upr = case_when(upr > 0 ~ 1,
                             upr < 0 ~ 0),
         won.upr = case_when(!is.na(won.upr) ~ won.upr,
                             is.na(won.upr) ~ won), 
         total.votes.upr = sum(won.upr * ec.votes))

predict.results <- merge(predict.results, my.predict.results, all = TRUE)

```

```{r}
#this chunk is for calculating national-level popular vote estimates

#bring in data on voting-eligible population estimates (from a blog) for each state
#note that this makes the assumption that a comparable proportion of the voting-eligible population in each state will in fact vote (NOT really a reasonable assumption for this election, but oh well)
#from  http://www[.]electproject.org/2020g
#skip the first row, which has the source info in it
population <- read_excel("./electoralcollege.xlsx", skip = 1, sheet = 2)

predict.results <- merge(predict.results, population, by = "state", all = TRUE)

predict.results <- predict.results %>% 
  filter(!is.na(my.predict)) %>% 
  mutate(pop.vote = vep * (my.predict * 0.01),
         total.pop = sum(vep),
         nat.pop.vote = sum(pop.vote) / total.pop)

trump.pop.vote <- ((unique(predict.results$nat.pop.vote)) + .5) * 100
biden.pop.vote <- 100 - trump.pop.vote 
```

```{r}
#this chunk makes the prediction maps

#calculate margin if 50% (i.e. 0) is inside the predictive range and sketchy fake z-score (distance from zero/ predictive interval size)
plot.data <- predict.results %>% 
  mutate(margin = case_when((upr > 0 & lwr < 0) ~ abs(my.predict) / interval.size, #when interval has 0
                            is.na(upr) ~ won, #this treats no-prediction states as having no interval
                            (upr < 0 | lwr > 0) ~ won), #0 outside interval->treated as no interval (sure)
         all.margin = abs(my.predict) / interval.size, #sketchy fake z-score
         new.won = case_when(won == 1 ~ won, #convert from 0-1 scale to -1 to 1 scale
                             won == 0 ~ -1),
         margin.by.won = all.margin * new.won) %>% 
  select(state, my.predict, won, margin, all.margin, margin.by.won)

states_map <- usmap::us_map()

#predicted results (0/1)
#copied from code for section1
won.map.plot <- plot_usmap(data = plot.data, regions = "state", values = "won") +
  scale_fill_gradient2(high = "red", 
                       mid = "blue",
                       limits = c(0, 1),
                       breaks = c(0, 1),
                       name = "Won") +
  theme_void() +
  labs(title = "Predicted victory by state", 
       subtitle  = "Biden is predicted to win blue states, Trump is predicted to win red states")
won.map.plot

ggsave("docs/images/won_map_plot.png", plot = won.map.plot, height = 5, width = 7.5)

#predicted results w/ margin (0/1 for states outside margin, purple for state inside margin)
margin.map.plot <- plot_usmap(data = plot.data, regions = "state", values = "margin") +
  scale_fill_gradient2(high = "red", 
                       mid = "blue",
                       name = "Margin") +
  theme_void() +
  labs(title = "title", 
       subtitle  = "subtitle")
margin.map.plot

#distance from margin as a proportion of size of predictive interval
#not sure if this is a legit way to calculate likelihood of winning but we're going with it
#a more sophisticated approach would calculate a proper z-score
uncertainty.map.plot <- plot_usmap(data = plot.data, regions = "state", values = "margin.by.won") +
  scale_fill_gradient2(high = "red", 
                       mid = "purple",
                       low = "blue",
                       name = "Distance") +
  theme_void() +
  labs(title = "Projected distance from 50% (normalized) by state", 
       subtitle = "Gray states do not have 2020 polls")
uncertainty.map.plot
ggsave("docs/images/uncertainty_map_plot.png", plot = uncertainty.map.plot, height = 5, width = 7.5)

```