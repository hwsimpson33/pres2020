## Examining Two Professional Prediction Models
### September 26, 2020

[Back to main page](https://hwsimpson33.github.io/pres2020/)

I was hoping to add to my state-level model this week, but an unusually busy schedule and some unexpected challenges in the R code mean I have not been able to successfully incorporate state-level poll results into my forecast (despite many hours of work!). Instead, I am seeking inspiration in the [538](https://fivethirtyeight.com/features/how-fivethirtyeights-2020-presidential-forecast-works-and-whats-different-because-of-covid-19/) and The [Economist](https://projects.economist.com/us-2020-forecast/president/how-this-works) prediction models. 
Both of these models are complex and statistically sophisticated. They both use many of the same inputs, but their approaches to combining these estimates are very different. The 538 model begins with polling data, combining polls based on reliability, house effects (regular biases caused by the methodologies of certain polling companies) and predictable changes like convention bumps (candidates normally poll higher immediately after their party’s convention). Then, Nate Silver adjusts these results based on contextual variables, like the partisan lean of each state, national trends in polls, and the demographic mix of respondents (among others). Finally, the 538 model incorporates economic and incumbency variables (called “fundamentals” in the political science literature). These fundamentals are not weighted very heavily, however, and the weighting they are given decreases to almost zero as the election approaches. The 538 model is based on polls and a careful weighting of their results, and uses fundamentals as a corrective.
The Economist’s model, however, begins with the fundamentals. It uses machine learning to fit a model with economic and incumbency variables. The Economist then adds state-level variables like results from the previous election, population density, and candidate home states in order to predict a “partisan lean” for each state relative to the national result. Then, the modelers turn to state-level polls, carefully correcting for biases like poll methodology, partisan non-response bias (people are less likely to talk with pollsters when their party has recently taken a hit in the news), and different numbers of polls in different states. The partisan lean prediction becomes the prior and state-level polls the observed data as The Economist uses Bayesian updating (a method of updating a hypothesis to reflect new information) to refine the model.
A few observations jumped out at me while reading these methodologies and comparing them with the far simpler models we have been working with. First, both models emphasized the uncertainty around their estimates rather than the point estimate itself. Intuitively, this makes sense. In closely-contested elections, the result (and the point estimate) is likely to be around 50%, so the margin of error is very important for determining how useful a prediction is. Both models used simulation in order to generate their uncertainty, 538 by varying uncertainty proportional to the cube root of the days until the election and The Economist by using a Markov Chain Monte Carlo technique that allows for random variation day-by-day. In future weeks, as I make my own predictions, I plan to think carefully about how I estimate uncertainty.
Finally, I would be curious to see more fully developed models of turnout. In post-Soviet elections (an area I have studied a lot), turnout is often a more interesting signal than the actual results. Because swings in turnout can be hard to predict ahead of time and can produce enormously different results, I would have imagined a turnout model would be at the center of any predictive model for the election. This issue is especially relevant because the popular narrative around the 2016 election (and some Twitter speculation about the 2020 election) point to turnout as a potentially game changing variable. Although 538 does address the issue by increasing uncertainty around the turnout estimate to reflect COVID-19, I would like to spend more time examining what polls tell us about likely turnout in 2020.
[Back to main page](https://hwsimpson33.github.io/pres2020/)
