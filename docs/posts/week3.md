## Examining two professional prediction models
### September 26, 2020

[Back to main page](https://hwsimpson33.github.io/pres2020/)

I was hoping to add to my state-level model this week, but an unusually busy schedule and some unexpected challenges in the R code mean I have not been able to successfully incorporate state-level poll results into my forecast (despite many hours of work!). Instead, I am seeking inspiration in the [538](https://fivethirtyeight.com/features/how-fivethirtyeights-2020-presidential-forecast-works-and-whats-different-because-of-covid-19/) and [The Economist](https://projects.economist.com/us-2020-forecast/president/how-this-works) prediction models. 
Both of these models are complex and statistically sophisticated. They both use many of the same inputs, but their approaches to combining these estimates are very different. The 538 model begins with polling data, combining polls based on reliability, house effects (regular biases caused by the methodologies of certain polling companies) and predictable changes like convention bumps (candidates normally poll higher immediately after their party’s convention). Then, Nate Silver adjusts these results based on contextual variables, like the partisan lean of each state, national trends in polls, and the demographic mix of respondents (among others). Finally, the 538 model incorporates economic and incumbency variables (called “fundamentals” in the political science literature). These fundamentals are not weighted very heavily, however, and the weighting they are given decreases to almost zero as the election approaches. The 538 model is based on polls and a careful weighting of their results, and uses fundamentals as a corrective.

The Economist’s model, however, begins with and relies heavily on fundamentals. It uses machine learning to fit a model with economic and incumbency variables. The Economist then adds state-level variables like results from the previous election, population density, and candidate home states in order to predict a “partisan lean” for each state relative to the national result. Next, the modelers turn to state-level polls, carefully correcting for biases like poll methodology, partisan non-response bias (people are less likely to talk with pollsters when their party has recently taken a hit in the news), and different numbers of polls in different states. The partisan lean prediction becomes the prior and state-level polls the observed data as The Economist uses Bayesian updating (a method of updating a hypothesis to reflect new information) to refine the model.

A few observations jumped out at me while reading these methodologies and comparing them with the far simpler models we have been working with. First, both models emphasized the uncertainty around their estimates rather than the point estimate itself. Intuitively, this makes sense. In closely-contested elections, the result (and the point estimate) are likely to be around 50%, so the margin of error is very important for determining how useful a prediction is. Both models used simulation in order to generate their uncertainty, 538 by varying uncertainty proportional to the cube root of the days until the election and The Economist by using a Markov Chain Monte Carlo technique that allows for random variation day-by-day between now and the election. In future weeks, as I make my own predictions, I plan to think carefully about how I estimate uncertainty.

Finally, I would be curious to see more fully developed models of turnout. In post-Soviet elections (an area I have studied a lot), turnout is often a more interesting signal than the actual results. Because swings in turnout can be hard to predict ahead of time and can produce enormously different results given similar underlying conditions, I would have imagined a turnout model would be at the center of any predictive model for the election. This issue is especially relevant because the popular narrative around the 2016 election, as well as Twitter speculation about the 2020 election, point to turnout as a potentially game-changing variable. Although 538 does address the issue by increasing uncertainty around the turnout estimate to reflect COVID-19, I would like to spend more time examining what polls tell us about likely turnout in 2020.

The Economist gives Biden an 85% chance of winning and 538 gives him a 77% chance of winning. This is a 12% spread! I would guess that this difference comes from the varying approaches of the two models. The 538 approach, while taking pains to build a statistical foundation and be replicable, strikes me as having more room for expert judgment in determining the combinations and weighting of factors. The Economist's model, however, takes a more rigorously statistical and political science-based approach. Picking between them, then, ultimately comes down to one's prior beliefs about the value of expertise versus the merits of rigorously constructed models with less room for judgment. Both provide insight into the dynamics of this presidential race. 

[Back to main page](https://hwsimpson33.github.io/pres2020/)
